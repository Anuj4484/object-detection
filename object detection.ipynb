{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e81e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "790c27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNet SSD model\n",
    "config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "frozen_model = 'frozen_inference_graph.pb'\n",
    "model = cv2.dnn_DetectionModel(frozen_model, config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f66652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class labels\n",
    "classLabels = []\n",
    "file_name = 'Labels.txt'\n",
    "with open(file_name, 'rt') as fpt:\n",
    "    classLabels = fpt.read().rstrip('\\n').split('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d2bc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Model 000001372C52DDD0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the model\n",
    "model.setInputSize(320, 320)\n",
    "model.setInputScale(1.0/127.5)\n",
    "model.setInputMean((127.5, 127.5, 127.5))\n",
    "model.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9d753f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not read frame\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a directory to save XML annotation files\n",
    "output_dir = 'annotations'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "font_scale = 3\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "# Initialize video capture from a video file\n",
    "video_file_path = 'videoplayback.mp4'\n",
    "cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Define a function to create an XML annotation for a detected object\n",
    "def create_xml_annotation(xml_file, width, height, detected_objects):\n",
    "    root = ET.Element(\"annotation\")\n",
    "    \n",
    "    folder = ET.SubElement(root, \"folder\")\n",
    "    folder.text = \"images\"\n",
    "    \n",
    "    filename = ET.SubElement(root, \"filename\")\n",
    "    filename.text = os.path.basename(xml_file).replace(\".xml\", \".jpg\")\n",
    "    \n",
    "    size = ET.SubElement(root, \"size\")\n",
    "    \n",
    "    width_elem = ET.SubElement(size, \"width\")\n",
    "    width_elem.text = str(width)\n",
    "    \n",
    "    height_elem = ET.SubElement(size, \"height\")\n",
    "    height_elem.text = str(height)\n",
    "    \n",
    "    for obj_info in detected_objects:\n",
    "        class_label = obj_info['class_label']\n",
    "        bbox = obj_info['bbox']\n",
    "        \n",
    "        object_elem = ET.SubElement(root, \"object\")\n",
    "        \n",
    "        name = ET.SubElement(object_elem, \"name\")\n",
    "        name.text = class_label\n",
    "        \n",
    "        bndbox = ET.SubElement(object_elem, \"bndbox\")\n",
    "        \n",
    "        xmin = ET.SubElement(bndbox, \"xmin\")\n",
    "        xmin.text = str(bbox[0])\n",
    "        \n",
    "        ymin = ET.SubElement(bndbox, \"ymin\")\n",
    "        ymin.text = str(bbox[1])\n",
    "        \n",
    "        xmax = ET.SubElement(bndbox, \"xmax\")\n",
    "        xmax.text = str(bbox[2])\n",
    "        \n",
    "        ymax = ET.SubElement(bndbox, \"ymax\")\n",
    "        ymax.text = str(bbox[3])\n",
    "\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(xml_file)\n",
    "\n",
    "# Define paths to the directories containing XML files\n",
    "model_predictions_dir = r'D:\\ORRT\\annotations'\n",
    "manual_annotations_dir = r'D:\\ORRT\\manual_annotations'\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame\")\n",
    "        break\n",
    "    \n",
    "    # Perform object detection on the frame to obtain ClassIndex, confidence, and bbox\n",
    "    ClassIndex, confidence, bbox = model.detect(frame, confThreshold=0.55)\n",
    "    \n",
    "    # List to store information about detected objects in the frame\n",
    "    detected_objects = []\n",
    "    \n",
    "    if len(ClassIndex) != 0:\n",
    "        for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):\n",
    "            if ClassInd <= 80:\n",
    "                cv2.rectangle(frame, boxes, (255, 0, 0), 2)\n",
    "                cv2.putText(frame, classLabels[ClassInd-1], (boxes[0]+10, boxes[1]+40), font, fontScale=font_scale, color=(0, 255, 0), thickness=1)\n",
    "                \n",
    "                # Append information about the detected object to the list\n",
    "                detected_objects.append({\n",
    "                    'class_label': classLabels[ClassInd-1],\n",
    "                    'bbox': boxes.tolist()\n",
    "                })\n",
    "\n",
    "    # Save the annotation as an XML file with information about all detected objects\n",
    "    filename = f\"frame_{frame_count}.xml\"\n",
    "    create_xml_annotation(os.path.join(output_dir, filename), frame.shape[1], frame.shape[0], detected_objects)\n",
    "    \n",
    "    cv2.imshow('Object Detection Tutorial', frame)\n",
    "    \n",
    "    # Save the video frame as an image (optional)\n",
    "    cv2.imwrite(f\"output_images/frame_{frame_count}.jpg\", frame)\n",
    "    \n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7170c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing model-generated annotation files\n",
    "model_annotations_dir = 'annotations'\n",
    "\n",
    "# Directory containing manual annotation files\n",
    "manual_annotations_dir = 'manual_annotations'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43cb9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse an XML annotation file\n",
    "def parse_annotation(annotation_file):\n",
    "    tree = ET.parse(annotation_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    filename = root.find('filename').text\n",
    "    class_label = root.find('object').find('name').text\n",
    "    \n",
    "    return filename, class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a938c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation match for frame_0.xml\n",
      "Annotation match for frame_1.xml\n",
      "Annotation match for frame_10.xml\n",
      "Annotation match for frame_100.xml\n",
      "Annotation match for frame_101.xml\n",
      "Annotation match for frame_102.xml\n",
      "Annotation match for frame_103.xml\n",
      "Annotation match for frame_104.xml\n",
      "Annotation match for frame_105.xml\n",
      "Annotation match for frame_106.xml\n",
      "Annotation match for frame_107.xml\n",
      "Annotation match for frame_108.xml\n",
      "Annotation match for frame_109.xml\n",
      "Annotation match for frame_11.xml\n",
      "Annotation match for frame_110.xml\n",
      "Annotation match for frame_111.xml\n",
      "Annotation match for frame_112.xml\n",
      "Annotation match for frame_113.xml\n",
      "Annotation match for frame_114.xml\n",
      "Annotation match for frame_115.xml\n",
      "Annotation match for frame_116.xml\n",
      "Annotation match for frame_117.xml\n",
      "Annotation match for frame_118.xml\n",
      "Annotation match for frame_119.xml\n",
      "Annotation match for frame_12.xml\n",
      "Annotation match for frame_120.xml\n",
      "Annotation match for frame_121.xml\n",
      "Annotation match for frame_122.xml\n",
      "Annotation match for frame_123.xml\n",
      "Annotation match for frame_124.xml\n",
      "Annotation match for frame_125.xml\n",
      "Annotation match for frame_126.xml\n",
      "Annotation match for frame_127.xml\n",
      "Annotation match for frame_128.xml\n",
      "Annotation match for frame_129.xml\n",
      "Annotation match for frame_13.xml\n",
      "Annotation match for frame_130.xml\n",
      "Annotation match for frame_131.xml\n",
      "Annotation match for frame_132.xml\n",
      "Annotation match for frame_133.xml\n",
      "Annotation match for frame_134.xml\n",
      "Annotation match for frame_135.xml\n",
      "Annotation match for frame_136.xml\n",
      "Annotation match for frame_137.xml\n",
      "Class label mismatch: Model: car, Manual: person\n",
      "Class label mismatch: Model: car, Manual: person\n",
      "Annotation match for frame_14.xml\n",
      "Annotation match for frame_140.xml\n",
      "Annotation match for frame_141.xml\n",
      "Annotation match for frame_142.xml\n",
      "Annotation match for frame_143.xml\n",
      "Annotation match for frame_144.xml\n",
      "Annotation match for frame_145.xml\n",
      "Annotation match for frame_146.xml\n",
      "Annotation match for frame_147.xml\n",
      "Annotation match for frame_148.xml\n",
      "Missing manual annotation for frame_149.xml\n",
      "Annotation match for frame_15.xml\n",
      "Missing manual annotation for frame_150.xml\n",
      "Missing manual annotation for frame_151.xml\n",
      "Missing manual annotation for frame_152.xml\n",
      "Missing manual annotation for frame_153.xml\n",
      "Missing manual annotation for frame_154.xml\n",
      "Missing manual annotation for frame_155.xml\n",
      "Missing manual annotation for frame_156.xml\n",
      "Missing manual annotation for frame_157.xml\n",
      "Missing manual annotation for frame_158.xml\n",
      "Missing manual annotation for frame_159.xml\n",
      "Annotation match for frame_16.xml\n",
      "Missing manual annotation for frame_160.xml\n",
      "Missing manual annotation for frame_161.xml\n",
      "Missing manual annotation for frame_162.xml\n",
      "Missing manual annotation for frame_163.xml\n",
      "Missing manual annotation for frame_164.xml\n",
      "Missing manual annotation for frame_165.xml\n",
      "Missing manual annotation for frame_166.xml\n",
      "Missing manual annotation for frame_167.xml\n",
      "Missing manual annotation for frame_168.xml\n",
      "Missing manual annotation for frame_169.xml\n",
      "Annotation match for frame_17.xml\n",
      "Missing manual annotation for frame_170.xml\n",
      "Missing manual annotation for frame_171.xml\n",
      "Missing manual annotation for frame_172.xml\n",
      "Missing manual annotation for frame_173.xml\n",
      "Missing manual annotation for frame_174.xml\n",
      "Missing manual annotation for frame_175.xml\n",
      "Missing manual annotation for frame_176.xml\n",
      "Missing manual annotation for frame_177.xml\n",
      "Missing manual annotation for frame_178.xml\n",
      "Missing manual annotation for frame_179.xml\n",
      "Annotation match for frame_18.xml\n",
      "Missing manual annotation for frame_180.xml\n",
      "Missing manual annotation for frame_181.xml\n",
      "Missing manual annotation for frame_182.xml\n",
      "Missing manual annotation for frame_183.xml\n",
      "Missing manual annotation for frame_184.xml\n",
      "Missing manual annotation for frame_185.xml\n",
      "Annotation match for frame_19.xml\n",
      "Annotation match for frame_2.xml\n",
      "Annotation match for frame_20.xml\n",
      "Annotation match for frame_21.xml\n",
      "Annotation match for frame_22.xml\n",
      "Annotation match for frame_23.xml\n",
      "Annotation match for frame_24.xml\n",
      "Annotation match for frame_25.xml\n",
      "Annotation match for frame_26.xml\n",
      "Annotation match for frame_27.xml\n",
      "Annotation match for frame_28.xml\n",
      "Annotation match for frame_29.xml\n",
      "Annotation match for frame_3.xml\n",
      "Annotation match for frame_30.xml\n",
      "Annotation match for frame_31.xml\n",
      "Annotation match for frame_32.xml\n",
      "Annotation match for frame_33.xml\n",
      "Annotation match for frame_34.xml\n",
      "Annotation match for frame_35.xml\n",
      "Annotation match for frame_36.xml\n",
      "Annotation match for frame_37.xml\n",
      "Annotation match for frame_38.xml\n",
      "Annotation match for frame_39.xml\n",
      "Annotation match for frame_4.xml\n",
      "Annotation match for frame_40.xml\n",
      "Annotation match for frame_41.xml\n",
      "Annotation match for frame_42.xml\n",
      "Annotation match for frame_43.xml\n",
      "Annotation match for frame_44.xml\n",
      "Annotation match for frame_45.xml\n",
      "Annotation match for frame_46.xml\n",
      "Annotation match for frame_47.xml\n",
      "Annotation match for frame_48.xml\n",
      "Annotation match for frame_49.xml\n",
      "Annotation match for frame_5.xml\n",
      "Annotation match for frame_50.xml\n",
      "Annotation match for frame_51.xml\n",
      "Annotation match for frame_52.xml\n",
      "Annotation match for frame_53.xml\n",
      "Annotation match for frame_54.xml\n",
      "Annotation match for frame_55.xml\n",
      "Annotation match for frame_56.xml\n",
      "Annotation match for frame_57.xml\n",
      "Annotation match for frame_58.xml\n",
      "Annotation match for frame_59.xml\n",
      "Annotation match for frame_6.xml\n",
      "Annotation match for frame_60.xml\n",
      "Annotation match for frame_61.xml\n",
      "Annotation match for frame_62.xml\n",
      "Annotation match for frame_63.xml\n",
      "Annotation match for frame_64.xml\n",
      "Annotation match for frame_65.xml\n",
      "Annotation match for frame_66.xml\n",
      "Annotation match for frame_67.xml\n",
      "Annotation match for frame_68.xml\n",
      "Annotation match for frame_69.xml\n",
      "Annotation match for frame_7.xml\n",
      "Annotation match for frame_70.xml\n",
      "Annotation match for frame_71.xml\n",
      "Annotation match for frame_72.xml\n",
      "Annotation match for frame_73.xml\n",
      "Annotation match for frame_74.xml\n",
      "Annotation match for frame_75.xml\n",
      "Annotation match for frame_76.xml\n",
      "Annotation match for frame_77.xml\n",
      "Annotation match for frame_78.xml\n",
      "Annotation match for frame_79.xml\n",
      "Annotation match for frame_8.xml\n",
      "Annotation match for frame_80.xml\n",
      "Annotation match for frame_81.xml\n",
      "Annotation match for frame_82.xml\n",
      "Annotation match for frame_83.xml\n",
      "Annotation match for frame_84.xml\n",
      "Annotation match for frame_85.xml\n",
      "Annotation match for frame_86.xml\n",
      "Annotation match for frame_87.xml\n",
      "Annotation match for frame_88.xml\n",
      "Annotation match for frame_89.xml\n",
      "Annotation match for frame_9.xml\n",
      "Annotation match for frame_90.xml\n",
      "Annotation match for frame_91.xml\n",
      "Annotation match for frame_92.xml\n",
      "Annotation match for frame_93.xml\n",
      "Annotation match for frame_94.xml\n",
      "Annotation match for frame_95.xml\n",
      "Annotation match for frame_96.xml\n",
      "Annotation match for frame_97.xml\n",
      "Annotation match for frame_98.xml\n",
      "Annotation match for frame_99.xml\n"
     ]
    }
   ],
   "source": [
    "# Compare model-generated annotations with manual annotations\n",
    "model_annotations = os.listdir(model_annotations_dir)\n",
    "manual_annotations = os.listdir(manual_annotations_dir)\n",
    "\n",
    "for model_annotation_file in model_annotations:\n",
    "    if model_annotation_file not in manual_annotations:\n",
    "        print(f\"Missing manual annotation for {model_annotation_file}\")\n",
    "    else:\n",
    "        model_annotation_path = os.path.join(model_annotations_dir, model_annotation_file)\n",
    "        manual_annotation_path = os.path.join(manual_annotations_dir, model_annotation_file)\n",
    "        \n",
    "        model_filename, model_class_label = parse_annotation(model_annotation_path)\n",
    "        manual_filename, manual_class_label = parse_annotation(manual_annotation_path)\n",
    "        \n",
    "        if model_filename != manual_filename:\n",
    "            print(f\"Filename mismatch: Model: {model_filename}, Manual: {manual_filename}\")\n",
    "        elif model_class_label != manual_class_label:\n",
    "            print(f\"Class label mismatch: Model: {model_class_label}, Manual: {manual_class_label}\")\n",
    "        else:\n",
    "            print(f\"Annotation match for {model_annotation_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9371319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize counters for accuracy calculation\n",
    "correct_matches = 0\n",
    "total_annotations = 0\n",
    "\n",
    "# Define an empty list to store class labels\n",
    "class_labels = []\n",
    "# Define an empty list to store true labels and predicted scores\n",
    "y_true = []\n",
    "y_scores = []\n",
    "\n",
    "# Loop through manual annotations to gather ground truth\n",
    "manual_annotations = os.listdir(manual_annotations_dir)\n",
    "for manual_annotation_file in manual_annotations:\n",
    "    manual_annotation_path = os.path.join(manual_annotations_dir, manual_annotation_file)\n",
    "    _, manual_class_label = parse_annotation(manual_annotation_path)\n",
    "    class_labels.append(manual_class_label)\n",
    "\n",
    "# Loop through model-generated annotations to gather predictions and ground truth\n",
    "model_annotations = os.listdir(model_annotations_dir)\n",
    "for model_annotation_file in model_annotations:\n",
    "    model_annotation_path = os.path.join(model_annotations_dir, model_annotation_file)\n",
    "    model_filename, model_class_label = parse_annotation(model_annotation_path)\n",
    "    \n",
    "\n",
    "# Check if manual annotation file exists for this frame\n",
    "    if model_annotation_file in manual_annotations:\n",
    "        # Load ground truth and prediction data\n",
    "        y_true.append(1 if model_class_label == class_labels[0] else 0)  # Set 1 for correct class, else 0\n",
    "        y_scores.append(confidence)  # Replace 'confidence' with the actual confidence score\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95847426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing ground truth annotation files\n",
    "ground_truth_dir = 'manual_annotations'\n",
    "\n",
    "# Directory containing model output annotation files\n",
    "model_output_dir = 'annotations'\n",
    "\n",
    "# Function to parse an XML annotation file\n",
    "def parse_annotation(annotation_file):\n",
    "    tree = ET.parse(annotation_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract bounding boxes, class labels, and other relevant information\n",
    "    # Modify this function according to your XML structure\n",
    "    bounding_boxes = [...]  # Extract bounding box coordinates\n",
    "    class_labels = [...]     # Extract class labels\n",
    "    confidence_scores = [...]  # Extract confidence scores\n",
    "\n",
    "    return bounding_boxes, class_labels, confidence_scores\n",
    "# Initialize lists to store ground truth and model predictions for all classes\n",
    "all_ground_truth = []  # List of ground truth annotations for all classes\n",
    "all_model_predictions = []  # List of model predictions for all classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac40b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IoU: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate IoU between two bounding boxes\n",
    "def calculate_iou(box1, box2):\n",
    "    # Check if the boxes are identical\n",
    "    if box1 == box2:\n",
    "        return 1.0  # IoU is 1 when boxes are identical\n",
    "    \n",
    "    # Calculate intersection coordinates\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "\n",
    "    # Calculate area of both bounding boxes\n",
    "    area_box1 = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
    "    area_box2 = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
    "\n",
    "    # Check if either bounding box has zero area\n",
    "    if area_box1 == 0 or area_box2 == 0:\n",
    "        return 0.0  # IoU is zero\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / float(area_box1 + area_box2 - intersection_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "# Function to parse the first bounding box from XML annotation\n",
    "def parse_first_bbox(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    first_bbox = None\n",
    "    \n",
    "    # Find the first object\n",
    "    first_object = root.find('object')\n",
    "    if first_object is not None:\n",
    "        bbox = first_object.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)\n",
    "        ymin = int(bbox.find('ymin').text)\n",
    "        xmax = int(bbox.find('xmax').text)\n",
    "        ymax = int(bbox.find('ymax').text)\n",
    "        \n",
    "        first_bbox = (xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    return first_bbox\n",
    "\n",
    "# Directory paths for ground truth and model output XML files\n",
    "ground_truth_dir = 'manual_annotations'\n",
    "model_output_dir = 'annotations'\n",
    "\n",
    "# List to store IoU values\n",
    "iou_values = []\n",
    "\n",
    "# Iterate over XML files in both directories\n",
    "for filename in os.listdir(ground_truth_dir):\n",
    "    ground_truth_file = os.path.join(ground_truth_dir, filename)\n",
    "    model_output_file = os.path.join(model_output_dir, filename)\n",
    "\n",
    "    # Parse the first bounding box information from XML files\n",
    "    gt_bbox = parse_first_bbox(ground_truth_file)\n",
    "    model_bbox = parse_first_bbox(model_output_file)\n",
    "\n",
    "    if gt_bbox is not None and model_bbox is not None:\n",
    "        # Calculate IoU between Ground Truth and Model Output\n",
    "        iou = calculate_iou(gt_bbox, model_bbox)\n",
    "        iou_values.append(iou)\n",
    "\n",
    "# Calculate the average IoU\n",
    "average_iou = sum(iou_values) / len(iou_values)\n",
    "print(f\"Average IoU: {average_iou:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f4024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fefa28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
